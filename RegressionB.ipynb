{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt  # Importing pyplot from matplotlib\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "from scipy.linalg import svd\n",
    "import os\n",
    "from scipy.io import loadmat\n",
    "from sklearn import model_selection\n",
    "from dtuimldmtools import (\n",
    "    draw_neural_net,\n",
    "    train_neural_net,\n",
    "    visualize_decision_boundary,\n",
    "    rlr_validate\n",
    ")\n",
    "import torch\n",
    "plt.rcParams.update({'font.size': 12})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     sbp  tobacco  adiposity  typea  obesity  alcohol  age  chd\n",
      "0    160    12.00      23.11     49    25.30    97.20   52    1\n",
      "1    144     0.01      28.61     55    28.87     2.06   63    1\n",
      "2    118     0.08      32.28     52    29.14     3.81   46    0\n",
      "3    170     7.50      38.03     51    31.99    24.26   58    1\n",
      "4    134    13.60      27.78     60    25.99    57.34   49    1\n",
      "..   ...      ...        ...    ...      ...      ...  ...  ...\n",
      "457  214     0.40      31.72     64    28.45     0.00   58    0\n",
      "458  182     4.20      32.10     52    28.61    18.72   52    1\n",
      "459  108     3.00      15.23     40    20.09    26.64   55    0\n",
      "460  118     5.40      30.79     64    27.35    23.97   40    0\n",
      "461  132     0.00      33.41     62    14.70     0.00   46    1\n",
      "\n",
      "[462 rows x 8 columns]\n",
      "       ldl\n",
      "0     5.73\n",
      "1     4.41\n",
      "2     3.48\n",
      "3     6.41\n",
      "4     3.50\n",
      "..     ...\n",
      "457   5.98\n",
      "458   4.41\n",
      "459   1.59\n",
      "460  11.61\n",
      "461   4.82\n",
      "\n",
      "[462 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "#filename = '../Data/SAheart.txt'\n",
    "#df = pd.read_csv(filename)\n",
    "\n",
    "url = \"https://hastie.su.domains/ElemStatLearn/datasets/SAheart.data\"\n",
    "df = pd.read_csv(url)  \n",
    "\n",
    "\n",
    "# Remove the first column \"row.names\"\n",
    "df = df.drop(columns = \"row.names\", axis = 1)\n",
    "\n",
    "# one hot encoding \n",
    "df['famhist'] = df['famhist']=='Present'\n",
    "\n",
    "# Specify the columns you want to include in the boxplot\n",
    "#columns_to_plot = ['sbp', 'tobacco', 'ldl', 'adiposity', 'typea', 'obesity', 'alcohol', 'age', 'chd', 'famhist']\n",
    "columns_x = ['sbp', 'tobacco', 'adiposity', 'typea', 'obesity', 'alcohol', 'age', 'chd']\n",
    "columns_y = ['ldl']\n",
    "\n",
    "print(df[columns_x])\n",
    "print(df[columns_y])\n",
    "X = StandardScaler().fit_transform(df[columns_x])\n",
    "y = StandardScaler().fit_transform(df[columns_y])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N, M = X.shape\n",
    "K = 10\n",
    "CV = model_selection.KFold(K,shuffle=True)\n",
    "# Define the model structure\n",
    "# binary cross entropy loss\n",
    "loss_fn = torch.nn.BCELoss()\n",
    "max_iter = 10000\n",
    "error_N = np.array([])\n",
    "error_ann = []\n",
    "error_baseline = []\n",
    "lambdas = np.power(10.,range(-5,9)) #10^-1 til 10^3\n",
    "#w_noreg = np.empty((M,K))\n",
    "reg_error = np.empty((K,1))\n",
    "lambda_low =  np.empty((K,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Crossvalidation fold: 1/10\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.7765414\t6.0637312e-06\n",
      "\t\tFinal loss:\n",
      "\t\t1897\t0.7744269\t9.235928e-07\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\trine\\anaconda3\\envs\\dtu02450\\Lib\\site-packages\\dtuimldmtools\\models\\nn_trainer.py:141: RuntimeWarning: overflow encountered in cast\n",
      "  if loss_value < best_final_loss:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t1000\t0.7634174\t3.7397047e-05\n",
      "\t\t2000\t0.7335822\t1.113133e-05\n",
      "\t\tFinal loss:\n",
      "\t\t2821\t0.7310763\t9.783589e-07\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.737012\t0.00010835857\n",
      "\t\t2000\t0.7045643\t1.8357403e-05\n",
      "\t\t3000\t0.696845\t5.901881e-06\n",
      "\t\t4000\t0.69370264\t4.4679487e-06\n",
      "\t\t5000\t0.68918234\t8.129621e-06\n",
      "\t\t6000\t0.6830763\t9.860184e-06\n",
      "\t\t7000\t0.67543554\t1.0236458e-05\n",
      "\t\t8000\t0.670044\t6.582724e-06\n",
      "\t\t9000\t0.6632367\t7.1894956e-06\n",
      "\t\t10000\t0.65932053\t5.06255e-06\n",
      "\t\tFinal loss:\n",
      "\t\t10000\t0.65932053\t5.06255e-06\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.7179044\t6.6416294e-05\n",
      "\t\t2000\t0.67867374\t3.9344133e-05\n",
      "\t\t3000\t0.6560336\t2.7619488e-05\n",
      "\t\t4000\t0.6391368\t1.6506401e-05\n",
      "\t\t5000\t0.6308447\t9.637261e-06\n",
      "\t\t6000\t0.62621295\t5.901293e-06\n",
      "\t\t7000\t0.6228915\t4.9758683e-06\n",
      "\t\t8000\t0.62018794\t3.5559608e-06\n",
      "\t\t9000\t0.6183488\t2.5062182e-06\n",
      "\t\t10000\t0.6170198\t1.9320137e-06\n",
      "\t\tFinal loss:\n",
      "\t\t10000\t0.6170198\t1.9320137e-06\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.72220534\t0.00018863128\n",
      "\t\t2000\t0.64782566\t4.793347e-05\n",
      "\t\t3000\t0.62940353\t1.7329838e-05\n",
      "\t\t4000\t0.6215624\t1.1794929e-05\n",
      "\t\t5000\t0.60315734\t1.5218211e-05\n",
      "\t\t6000\t0.59302753\t1.2864995e-05\n",
      "\t\t7000\t0.5843136\t1.173078e-05\n",
      "\t\t8000\t0.57829946\t9.173041e-06\n",
      "\t\t9000\t0.573552\t7.274484e-06\n",
      "\t\t10000\t0.56975466\t6.2768354e-06\n",
      "\t\tFinal loss:\n",
      "\t\t10000\t0.56975466\t6.2768354e-06\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.7302463\t7.019056e-05\n",
      "\t\t2000\t0.67036396\t0.00010348502\n",
      "\t\t3000\t0.6271745\t3.079097e-05\n",
      "\t\t4000\t0.6120854\t1.6262133e-05\n",
      "\t\t5000\t0.60101074\t2.3900366e-05\n",
      "\t\t6000\t0.58549166\t2.371947e-05\n",
      "\t\t7000\t0.57727957\t9.808741e-06\n",
      "\t\t8000\t0.57099974\t2.1085621e-05\n",
      "\t\t9000\t0.5611295\t1.30652115e-05\n",
      "\t\t10000\t0.55436295\t1.2257035e-05\n",
      "\t\tFinal loss:\n",
      "\t\t10000\t0.55436295\t1.2257035e-05\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.6429667\t0.00010131361\n",
      "\t\t2000\t0.59417564\t3.2200034e-05\n",
      "\t\t3000\t0.57161\t3.3366894e-05\n",
      "\t\t4000\t0.559323\t1.5984599e-05\n",
      "\t\t5000\t0.5519211\t1.1339332e-05\n",
      "\t\t6000\t0.54649806\t8.725246e-06\n",
      "\t\t7000\t0.54181993\t8.910586e-06\n",
      "\t\t8000\t0.53736717\t7.3206515e-06\n",
      "\t\t9000\t0.5338463\t6.029135e-06\n",
      "\t\t10000\t0.5304306\t2.011388e-05\n",
      "\t\tFinal loss:\n",
      "\t\t10000\t0.5304306\t2.011388e-05\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.6634364\t0.00017156932\n",
      "\t\t2000\t0.5728148\t6.5758875e-05\n",
      "\t\t3000\t0.54471266\t3.271671e-05\n",
      "\t\t4000\t0.5255634\t4.2300493e-05\n",
      "\t\t5000\t0.50982803\t2.3732426e-05\n",
      "\t\t6000\t0.49866185\t1.7869294e-05\n",
      "\t\t7000\t0.49012023\t2.0795269e-05\n",
      "\t\t8000\t0.4807776\t1.7914139e-05\n",
      "\t\t9000\t0.47202215\t2.3991694e-05\n",
      "\t\t10000\t0.46081212\t1.953101e-05\n",
      "\t\tFinal loss:\n",
      "\t\t10000\t0.46081212\t1.953101e-05\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.66478544\t0.0001463933\n",
      "\t\t2000\t0.5795244\t0.000117956144\n",
      "\t\t3000\t0.52608186\t0.000119742894\n",
      "\t\t4000\t0.50000936\t2.1099204e-05\n",
      "\t\t5000\t0.4892663\t1.7298786e-05\n",
      "\t\t6000\t0.47722366\t2.766431e-05\n",
      "\t\t7000\t0.46505973\t2.2364391e-05\n",
      "\t\t8000\t0.4561857\t1.6593383e-05\n",
      "\t\t9000\t0.4458152\t1.9452695e-05\n",
      "\t\t10000\t0.43872997\t1.358554e-05\n",
      "\t\tFinal loss:\n",
      "\t\t10000\t0.43872997\t1.358554e-05\n",
      "\n",
      "Crossvalidation fold: 2/10\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\trine\\anaconda3\\envs\\dtu02450\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:610: UserWarning: Using a target size (torch.Size([47, 1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t1000\t0.8432254\t0.000118739204\n",
      "\t\t2000\t0.80009264\t2.7041744e-05\n",
      "\t\t3000\t0.78727037\t3.6340914e-06\n",
      "\t\t4000\t0.7856996\t1.8965433e-06\n",
      "\t\tFinal loss:\n",
      "\t\t4912\t0.78456664\t9.876276e-07\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.7729901\t1.9122715e-05\n",
      "\t\t2000\t0.769241\t3.4093289e-06\n",
      "\t\t3000\t0.7631522\t8.122669e-06\n",
      "\t\t4000\t0.7580777\t6.7617934e-06\n",
      "\t\t5000\t0.7548992\t1.737053e-06\n",
      "\t\tFinal loss:\n",
      "\t\t5409\t0.7544725\t9.4802004e-07\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.7788819\t3.6501526e-05\n",
      "\t\t2000\t0.7638066\t1.4904713e-05\n",
      "\t\t3000\t0.75032556\t1.6920088e-05\n",
      "\t\t4000\t0.7423964\t5.8609035e-06\n",
      "\t\t5000\t0.7327129\t1.3096837e-05\n",
      "\t\t6000\t0.7223348\t2.128884e-05\n",
      "\t\t7000\t0.71549016\t6.747743e-06\n",
      "\t\t8000\t0.71155727\t4.523369e-06\n",
      "\t\t9000\t0.70878625\t3.3637473e-06\n",
      "\t\t10000\t0.7068122\t2.3612017e-06\n",
      "\t\tFinal loss:\n",
      "\t\t10000\t0.7068122\t2.3612017e-06\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.74509996\t3.775645e-05\n",
      "\t\t2000\t0.7028735\t2.0267118e-05\n",
      "\t\t3000\t0.6946857\t8.408416e-06\n",
      "\t\t4000\t0.6844342\t1.4281903e-05\n",
      "\t\t5000\t0.6781785\t7.997864e-06\n",
      "\t\t6000\t0.6676199\t3.115751e-05\n",
      "\t\t7000\t0.63228494\t1.3668767e-05\n",
      "\t\t8000\t0.6278507\t4.461898e-06\n",
      "\t\t9000\t0.62547225\t3.6212132e-06\n",
      "\t\t10000\t0.6234194\t3.0594858e-06\n",
      "\t\tFinal loss:\n",
      "\t\t10000\t0.6234194\t3.0594858e-06\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.7442285\t6.3346524e-05\n",
      "\t\t2000\t0.696407\t6.273266e-05\n",
      "\t\t3000\t0.6667131\t2.6908898e-05\n",
      "\t\t4000\t0.6522627\t3.0611816e-05\n",
      "\t\t5000\t0.61959773\t2.347199e-05\n",
      "\t\t6000\t0.59606445\t2.6198522e-05\n",
      "\t\t7000\t0.5871352\t1.0151672e-05\n",
      "\t\t8000\t0.5821793\t7.0643036e-06\n",
      "\t\t9000\t0.5778359\t7.117403e-06\n",
      "\t\t10000\t0.56990767\t2.5309291e-05\n",
      "\t\tFinal loss:\n",
      "\t\t10000\t0.56990767\t2.5309291e-05\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.72408533\t9.6631e-05\n",
      "\t\t2000\t0.6815814\t4.0837724e-05\n",
      "\t\t3000\t0.6599474\t1.8514696e-05\n",
      "\t\t4000\t0.6443476\t2.5067919e-05\n",
      "\t\t5000\t0.6278441\t3.4270513e-05\n",
      "\t\t6000\t0.6055446\t2.992227e-05\n",
      "\t\t7000\t0.5880087\t3.4362212e-05\n",
      "\t\t8000\t0.575126\t1.5856293e-05\n",
      "\t\t9000\t0.5681228\t9.5471805e-06\n",
      "\t\t10000\t0.56363815\t6.5564473e-06\n",
      "\t\tFinal loss:\n",
      "\t\t10000\t0.56363815\t6.5564473e-06\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.6743671\t9.951279e-05\n",
      "\t\t2000\t0.62991023\t4.2484386e-05\n",
      "\t\t3000\t0.58914787\t4.603066e-05\n",
      "\t\t4000\t0.5748351\t3.411284e-05\n",
      "\t\t5000\t0.5624365\t1.40945795e-05\n",
      "\t\t6000\t0.55473274\t1.1819085e-05\n",
      "\t\t7000\t0.5480114\t1.4791866e-05\n",
      "\t\t8000\t0.5381832\t1.4618996e-05\n",
      "\t\t9000\t0.5268774\t1.0407678e-05\n",
      "\t\t10000\t0.5225345\t8.783186e-06\n",
      "\t\tFinal loss:\n",
      "\t\t10000\t0.5225345\t8.783186e-06\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.71116275\t0.000105174186\n",
      "\t\t2000\t0.62988824\t0.000120351484\n",
      "\t\t3000\t0.57813793\t5.2267762e-05\n",
      "\t\t4000\t0.55731636\t2.6201913e-05\n",
      "\t\t5000\t0.54136693\t3.203815e-05\n",
      "\t\t6000\t0.52645487\t2.5813244e-05\n",
      "\t\t7000\t0.51528823\t1.5384197e-05\n",
      "\t\t8000\t0.5074018\t1.515344e-05\n",
      "\t\t9000\t0.5001799\t1.4418929e-05\n",
      "\t\t10000\t0.4929663\t1.37835705e-05\n",
      "\t\tFinal loss:\n",
      "\t\t10000\t0.4929663\t1.37835705e-05\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.6593842\t0.00020840607\n",
      "\t\t2000\t0.54828703\t0.0001073946\n",
      "\t\t3000\t0.5062015\t5.14536e-05\n",
      "\t\t4000\t0.4693328\t9.727152e-05\n",
      "\t\t5000\t0.44138235\t5.0300183e-05\n",
      "\t\t6000\t0.42487684\t2.56017e-05\n",
      "\t\t7000\t0.41639084\t1.7248785e-05\n",
      "\t\t8000\t0.40817466\t2.5919175e-05\n",
      "\t\t9000\t0.39762104\t2.3834033e-05\n",
      "\t\t10000\t0.3893886\t1.8215283e-05\n",
      "\t\tFinal loss:\n",
      "\t\t10000\t0.3893886\t1.8215283e-05\n",
      "\n",
      "Crossvalidation fold: 3/10\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.8178912\t3.1117088e-05\n",
      "\t\t2000\t0.8053728\t7.918875e-06\n",
      "\t\t3000\t0.7994381\t8.350446e-06\n",
      "\t\t4000\t0.7934277\t4.58248e-06\n",
      "\t\tFinal loss:\n",
      "\t\t4669\t0.79207766\t9.782622e-07\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.79251796\t1.3763095e-05\n",
      "\t\t2000\t0.7824367\t1.584482e-05\n",
      "\t\t3000\t0.77125466\t3.608972e-05\n",
      "\t\t4000\t0.7549354\t7.5005078e-06\n",
      "\t\t5000\t0.75081736\t4.048687e-06\n",
      "\t\t6000\t0.7483871\t2.7875371e-06\n",
      "\t\t7000\t0.7464448\t2.7149395e-06\n",
      "\t\t8000\t0.7439309\t4.246406e-06\n",
      "\t\t9000\t0.7403743\t4.991353e-06\n",
      "\t\t10000\t0.7368564\t4.368065e-06\n",
      "\t\tFinal loss:\n",
      "\t\t10000\t0.7368564\t4.368065e-06\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.7512119\t6.5851724e-05\n",
      "\t\t2000\t0.7312028\t1.7770148e-05\n",
      "\t\t3000\t0.7208655\t1.1079645e-05\n",
      "\t\t4000\t0.7141338\t7.845579e-06\n",
      "\t\t5000\t0.7091141\t6.724362e-06\n",
      "\t\t6000\t0.7047482\t5.8356964e-06\n",
      "\t\t7000\t0.7003322\t7.404437e-06\n",
      "\t\t8000\t0.69347984\t9.970109e-06\n",
      "\t\t9000\t0.6875123\t7.282421e-06\n",
      "\t\t10000\t0.6830343\t5.846687e-06\n",
      "\t\tFinal loss:\n",
      "\t\t10000\t0.6830343\t5.846687e-06\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.74609196\t5.815591e-05\n",
      "\t\t2000\t0.72384876\t2.0997293e-05\n",
      "\t\t3000\t0.7065099\t1.9656638e-05\n",
      "\t\t4000\t0.69786197\t8.540964e-06\n",
      "\t\t5000\t0.69060904\t1.3118547e-05\n",
      "\t\t6000\t0.67885315\t1.9842852e-05\n",
      "\t\t7000\t0.66929775\t1.4337729e-05\n",
      "\t\t8000\t0.6613335\t1.1085617e-05\n",
      "\t\t9000\t0.65484166\t8.464925e-06\n",
      "\t\t10000\t0.6498576\t6.878919e-06\n",
      "\t\tFinal loss:\n",
      "\t\t10000\t0.6498576\t6.878919e-06\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.7271421\t8.0653066e-05\n",
      "\t\t2000\t0.6703877\t6.276702e-05\n",
      "\t\t3000\t0.620604\t5.1092247e-05\n",
      "\t\t4000\t0.6006105\t2.9572675e-05\n",
      "\t\t5000\t0.58225995\t2.9071598e-05\n",
      "\t\t6000\t0.5688943\t1.927782e-05\n",
      "\t\t7000\t0.5595789\t1.3420958e-05\n",
      "\t\t8000\t0.5532931\t8.618092e-06\n",
      "\t\t9000\t0.5497685\t4.7703566e-06\n",
      "\t\t10000\t0.5475286\t4.4632907e-06\n",
      "\t\tFinal loss:\n",
      "\t\t10000\t0.5475286\t4.4632907e-06\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.7299744\t8.834081e-05\n",
      "\t\t2000\t0.69607323\t2.8685175e-05\n",
      "\t\t3000\t0.671251\t4.146618e-05\n",
      "\t\t4000\t0.6409232\t5.1053354e-05\n",
      "\t\t5000\t0.6075051\t4.414927e-05\n",
      "\t\t6000\t0.5856539\t3.6332185e-05\n",
      "\t\t7000\t0.5728623\t1.3213803e-05\n",
      "\t\t8000\t0.56736714\t7.248729e-06\n",
      "\t\t9000\t0.563438\t8.25135e-06\n",
      "\t\t10000\t0.54856837\t2.553325e-05\n",
      "\t\tFinal loss:\n",
      "\t\t10000\t0.54856837\t2.553325e-05\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.72887176\t0.00018821427\n",
      "\t\t2000\t0.64043796\t0.00010301629\n",
      "\t\t3000\t0.60030675\t3.9515984e-05\n",
      "\t\t4000\t0.5805792\t3.7470993e-05\n",
      "\t\t5000\t0.53657866\t4.82076e-05\n",
      "\t\t6000\t0.52349025\t1.5598589e-05\n",
      "\t\t7000\t0.5171332\t9.681726e-06\n",
      "\t\t8000\t0.5118957\t9.8972205e-06\n",
      "\t\t9000\t0.5074022\t7.635505e-06\n",
      "\t\t10000\t0.49935186\t1.0742647e-05\n",
      "\t\tFinal loss:\n",
      "\t\t10000\t0.49935186\t1.0742647e-05\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.6824409\t0.00017648375\n",
      "\t\t2000\t0.5978106\t9.3215385e-05\n",
      "\t\t3000\t0.5568242\t5.3090964e-05\n",
      "\t\t4000\t0.5336677\t3.7190952e-05\n",
      "\t\t5000\t0.5104011\t2.3238681e-05\n",
      "\t\t6000\t0.5016123\t1.3902463e-05\n",
      "\t\t7000\t0.4918308\t1.6481477e-05\n",
      "\t\t8000\t0.48510405\t1.173393e-05\n",
      "\t\t9000\t0.47985566\t1.0992791e-05\n",
      "\t\t10000\t0.47407606\t1.074963e-05\n",
      "\t\tFinal loss:\n",
      "\t\t10000\t0.47407606\t1.074963e-05\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.7095369\t0.0001619354\n",
      "\t\t2000\t0.60620415\t0.00011895834\n",
      "\t\t3000\t0.54974204\t8.5755186e-05\n",
      "\t\t4000\t0.47850326\t0.0001018836\n",
      "\t\t5000\t0.45413545\t2.3755434e-05\n",
      "\t\t6000\t0.44635132\t1.3286806e-05\n",
      "\t\t7000\t0.4412405\t1.0266298e-05\n",
      "\t\t8000\t0.43726635\t8.110497e-06\n",
      "\t\t9000\t0.43396503\t7.0734213e-06\n",
      "\t\t10000\t0.43108258\t6.152859e-06\n",
      "\t\tFinal loss:\n",
      "\t\t10000\t0.43108258\t6.152859e-06\n",
      "\n",
      "Crossvalidation fold: 4/10\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\trine\\anaconda3\\envs\\dtu02450\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:610: UserWarning: Using a target size (torch.Size([46, 1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t1000\t0.6746553\t4.4790577e-05\n",
      "\t\tFinal loss:\n",
      "\t\t1978\t0.66985154\t9.787997e-07\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.71009004\t0.00019252028\n",
      "\t\t2000\t0.6592951\t2.422839e-05\n",
      "\t\t3000\t0.65173304\t3.4753011e-06\n",
      "\t\t4000\t0.650198\t2.9334803e-06\n",
      "\t\t5000\t0.6485474\t2.2057113e-06\n",
      "\t\t6000\t0.64742273\t1.3809655e-06\n",
      "\t\t7000\t0.6465104\t1.4751083e-06\n",
      "\t\t8000\t0.645633\t1.2924742e-06\n",
      "\t\t9000\t0.64407194\t3.516639e-06\n",
      "\t\t10000\t0.64200366\t2.692399e-06\n",
      "\t\tFinal loss:\n",
      "\t\t10000\t0.64200366\t2.692399e-06\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.65318584\t7.117165e-05\n",
      "\t\t2000\t0.6365738\t1.685375e-05\n",
      "\t\t3000\t0.6249294\t2.8612641e-05\n",
      "\t\t4000\t0.6049202\t1.7834167e-05\n",
      "\t\t5000\t0.5992644\t3.978505e-06\n",
      "\t\tFinal loss:\n",
      "\t\t5737\t0.59826285\t9.962943e-07\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.6660664\t9.395309e-05\n",
      "\t\t2000\t0.62457246\t4.237033e-05\n",
      "\t\t3000\t0.60407585\t2.3088432e-05\n",
      "\t\t4000\t0.5950193\t1.172006e-05\n",
      "\t\t5000\t0.58893245\t9.209838e-06\n",
      "\t\t6000\t0.58347976\t1.0930332e-05\n",
      "\t\t7000\t0.5782084\t7.628236e-06\n",
      "\t\t8000\t0.5741055\t7.05983e-06\n",
      "\t\t9000\t0.5697712\t7.845804e-06\n",
      "\t\t10000\t0.5656563\t7.5867656e-06\n",
      "\t\tFinal loss:\n",
      "\t\t10000\t0.5656563\t7.5867656e-06\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.58304477\t0.00016119066\n",
      "\t\t2000\t0.52926415\t1.9144685e-05\n",
      "\t\t3000\t0.5119081\t2.5848172e-05\n",
      "\t\t4000\t0.5041261\t7.685126e-06\n",
      "\t\t5000\t0.50151\t4.040896e-06\n",
      "\t\t6000\t0.4996063\t3.579084e-06\n",
      "\t\t7000\t0.4978573\t3.4120753e-06\n",
      "\t\t8000\t0.4959957\t3.5450526e-06\n",
      "\t\t9000\t0.4943414\t3.5569158e-06\n",
      "\t\t10000\t0.4921928\t5.025633e-06\n",
      "\t\tFinal loss:\n",
      "\t\t10000\t0.4921928\t5.025633e-06\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.63356644\t0.0001459877\n",
      "\t\t2000\t0.5838707\t4.6957055e-05\n",
      "\t\t3000\t0.56468725\t2.9131883e-05\n",
      "\t\t4000\t0.55011666\t2.3944578e-05\n",
      "\t\t5000\t0.53541905\t3.2950626e-05\n",
      "\t\t6000\t0.4992673\t0.000105285806\n",
      "\t\t7000\t0.46465015\t7.215147e-05\n",
      "\t\t8000\t0.4451277\t2.5374276e-05\n",
      "\t\t9000\t0.43757194\t1.0624796e-05\n",
      "\t\t10000\t0.43460384\t4.8001243e-06\n",
      "\t\tFinal loss:\n",
      "\t\t10000\t0.43460384\t4.8001243e-06\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.60060954\t0.00010746565\n",
      "\t\t2000\t0.5327849\t0.00011689441\n",
      "\t\t3000\t0.5072504\t2.984547e-05\n",
      "\t\t4000\t0.4870267\t3.1941403e-05\n",
      "\t\t5000\t0.47454926\t2.405233e-05\n",
      "\t\t6000\t0.4646458\t1.750988e-05\n",
      "\t\t7000\t0.45759276\t1.5500338e-05\n",
      "\t\t8000\t0.45237637\t9.3548e-06\n",
      "\t\t9000\t0.44863755\t9.764895e-06\n",
      "\t\t10000\t0.4438865\t9.198028e-06\n",
      "\t\tFinal loss:\n",
      "\t\t10000\t0.4438865\t9.198028e-06\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.60321957\t0.00014809554\n",
      "\t\t2000\t0.5253012\t0.00010517336\n",
      "\t\t3000\t0.47497305\t0.00015746588\n",
      "\t\t4000\t0.44798705\t2.8671437e-05\n",
      "\t\t5000\t0.4375319\t1.6415357e-05\n",
      "\t\t6000\t0.4311674\t2.2187052e-05\n",
      "\t\t7000\t0.42460087\t9.896555e-06\n",
      "\t\t8000\t0.42059612\t1.0203353e-05\n",
      "\t\t9000\t0.41561952\t1.3480505e-05\n",
      "\t\t10000\t0.4109772\t9.499474e-06\n",
      "\t\tFinal loss:\n",
      "\t\t10000\t0.4109772\t9.499474e-06\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.5249643\t0.00019400287\n",
      "\t\t2000\t0.47210997\t5.1444884e-05\n",
      "\t\t3000\t0.44668818\t4.7034264e-05\n",
      "\t\t4000\t0.42950577\t2.2272885e-05\n",
      "\t\t5000\t0.42153898\t1.8805542e-05\n",
      "\t\t6000\t0.4105954\t2.562121e-05\n",
      "\t\t7000\t0.40260684\t1.7247152e-05\n",
      "\t\t8000\t0.395526\t1.6651758e-05\n",
      "\t\t9000\t0.38946098\t1.4845043e-05\n",
      "\t\t10000\t0.38413283\t1.2568349e-05\n",
      "\t\tFinal loss:\n",
      "\t\t10000\t0.38413283\t1.2568349e-05\n",
      "\n",
      "Crossvalidation fold: 5/10\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.77975345\t8.102614e-06\n",
      "\t\t2000\t0.77675855\t4.066944e-06\n",
      "\t\t3000\t0.7729665\t4.9351147e-06\n",
      "\t\tFinal loss:\n",
      "\t\t3792\t0.7711915\t9.2746757e-07\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.7837745\t2.1901404e-05\n",
      "\t\t2000\t0.7732801\t7.939206e-06\n",
      "\t\t3000\t0.7695355\t4.802209e-06\n",
      "\t\t4000\t0.76318264\t1.7650313e-05\n",
      "\t\t5000\t0.75209177\t2.1397948e-06\n",
      "\t\t6000\t0.7439284\t7.1307613e-06\n",
      "\t\t7000\t0.7376524\t4.7673634e-06\n",
      "\t\t8000\t0.734928\t2.757484e-06\n",
      "\t\t9000\t0.7331127\t2.1138871e-06\n",
      "\t\t10000\t0.7317437\t1.62911e-06\n",
      "\t\tFinal loss:\n",
      "\t\t10000\t0.7317437\t1.62911e-06\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.77288747\t5.960977e-05\n",
      "\t\t2000\t0.748334\t2.038993e-05\n",
      "\t\t3000\t0.7362416\t1.2062596e-05\n",
      "\t\t4000\t0.72572887\t1.7657796e-05\n",
      "\t\t5000\t0.70750046\t3.4876957e-05\n",
      "\t\t6000\t0.6976475\t1.9991769e-05\n",
      "\t\t7000\t0.68376064\t2.632519e-05\n",
      "\t\t8000\t0.6703488\t1.662699e-05\n",
      "\t\t9000\t0.66049194\t1.2363112e-05\n",
      "\t\t10000\t0.65395045\t8.658748e-06\n",
      "\t\tFinal loss:\n",
      "\t\t10000\t0.65395045\t8.658748e-06\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.7288047\t9.232574e-05\n",
      "\t\t2000\t0.6853252\t3.617937e-05\n",
      "\t\t3000\t0.67113584\t2.2380022e-05\n",
      "\t\t4000\t0.6605718\t8.030574e-06\n",
      "\t\t5000\t0.6545115\t9.015589e-06\n",
      "\t\t6000\t0.6502765\t4.7663216e-06\n",
      "\t\t7000\t0.6484795\t1.4706292e-06\n",
      "\t\tFinal loss:\n",
      "\t\t7358\t0.6481847\t9.195618e-07\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.72743565\t6.2924446e-05\n",
      "\t\t2000\t0.69859546\t3.813689e-05\n",
      "\t\t3000\t0.6751935\t2.5070287e-05\n",
      "\t\t4000\t0.66588885\t1.0025176e-05\n",
      "\t\t5000\t0.6600864\t8.939447e-06\n",
      "\t\t6000\t0.6517502\t1.3626342e-05\n",
      "\t\t7000\t0.6401471\t1.5921703e-05\n",
      "\t\t8000\t0.6318961\t8.583652e-06\n",
      "\t\t9000\t0.62754345\t6.4586598e-06\n",
      "\t\t10000\t0.62349945\t6.596146e-06\n",
      "\t\tFinal loss:\n",
      "\t\t10000\t0.62349945\t6.596146e-06\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.7412312\t5.837645e-05\n",
      "\t\t2000\t0.70702565\t7.257993e-05\n",
      "\t\t3000\t0.6449678\t0.00014368455\n",
      "\t\t4000\t0.59687775\t3.2553537e-05\n",
      "\t\t5000\t0.57775676\t2.8060265e-05\n",
      "\t\t6000\t0.56469095\t2.1532283e-05\n",
      "\t\t7000\t0.5552585\t1.2666639e-05\n",
      "\t\t8000\t0.5497425\t7.806383e-06\n",
      "\t\t9000\t0.5459944\t8.187468e-06\n",
      "\t\t10000\t0.5416583\t7.4827353e-06\n",
      "\t\tFinal loss:\n",
      "\t\t10000\t0.5416583\t7.4827353e-06\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.7281833\t0.00016908156\n",
      "\t\t2000\t0.63488805\t0.00012916513\n",
      "\t\t3000\t0.58458763\t4.4656554e-05\n",
      "\t\t4000\t0.5699877\t1.7044913e-05\n",
      "\t\t5000\t0.5616816\t1.0611708e-05\n",
      "\t\t6000\t0.5372918\t5.9568723e-05\n",
      "\t\t7000\t0.5172674\t2.3160663e-05\n",
      "\t\t8000\t0.50613403\t1.6486765e-05\n",
      "\t\t9000\t0.50017977\t8.460746e-06\n",
      "\t\t10000\t0.49645856\t5.642772e-06\n",
      "\t\tFinal loss:\n",
      "\t\t10000\t0.49645856\t5.642772e-06\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.7027859\t8.098885e-05\n",
      "\t\t2000\t0.64496356\t7.6052194e-05\n",
      "\t\t3000\t0.6131688\t3.314668e-05\n",
      "\t\t4000\t0.5911487\t3.8111728e-05\n",
      "\t\t5000\t0.56977093\t4.592238e-05\n",
      "\t\t6000\t0.55217683\t2.3207604e-05\n",
      "\t\t7000\t0.53965527\t2.6838503e-05\n",
      "\t\t8000\t0.52362686\t3.653822e-05\n",
      "\t\t9000\t0.51284516\t1.661968e-05\n",
      "\t\t10000\t0.50526464\t1.2976221e-05\n",
      "\t\tFinal loss:\n",
      "\t\t10000\t0.50526464\t1.2976221e-05\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.6831364\t0.00019200357\n",
      "\t\t2000\t0.5854967\t0.00013354619\n",
      "\t\t3000\t0.53129596\t4.9584316e-05\n",
      "\t\t4000\t0.49286905\t9.540785e-05\n",
      "\t\t5000\t0.44933832\t0.0001240785\n",
      "\t\t6000\t0.41335166\t4.650182e-05\n",
      "\t\t7000\t0.3980368\t4.140321e-05\n",
      "\t\t8000\t0.3857919\t1.7535383e-05\n",
      "\t\t9000\t0.38035414\t1.1439574e-05\n",
      "\t\t10000\t0.37671378\t8.306619e-06\n",
      "\t\tFinal loss:\n",
      "\t\t10000\t0.37671378\t8.306619e-06\n",
      "\n",
      "Crossvalidation fold: 6/10\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.7375839\t2.3434544e-05\n",
      "\t\tFinal loss:\n",
      "\t\t1530\t0.73450273\t9.73795e-07\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.7293822\t2.0592854e-05\n",
      "\t\t2000\t0.71899223\t1.1108512e-05\n",
      "\t\t3000\t0.7110398\t1.00591915e-05\n",
      "\t\t4000\t0.70525783\t6.3385614e-06\n",
      "\t\t5000\t0.70189965\t3.3118317e-06\n",
      "\t\t6000\t0.69804096\t2.9031994e-06\n",
      "\t\t7000\t0.6964272\t2.3108253e-06\n",
      "\t\t8000\t0.6945891\t3.0892518e-06\n",
      "\t\t9000\t0.6926478\t2.7536987e-06\n",
      "\t\t10000\t0.6911004\t1.983654e-06\n",
      "\t\tFinal loss:\n",
      "\t\t10000\t0.6911004\t1.983654e-06\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.7378864\t7.067534e-05\n",
      "\t\t2000\t0.710671\t2.885077e-05\n",
      "\t\t3000\t0.6824875\t2.6199637e-05\n",
      "\t\t4000\t0.66464996\t1.2106417e-05\n",
      "\t\t5000\t0.65759045\t9.335934e-06\n",
      "\t\t6000\t0.6520647\t7.678305e-06\n",
      "\t\t7000\t0.64779377\t5.4286643e-06\n",
      "\t\t8000\t0.64483064\t3.882237e-06\n",
      "\t\t9000\t0.6427065\t3.0604128e-06\n",
      "\t\t10000\t0.64099133\t2.6036635e-06\n",
      "\t\tFinal loss:\n",
      "\t\t10000\t0.64099133\t2.6036635e-06\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.72936195\t4.2166583e-05\n",
      "\t\t2000\t0.6884812\t7.280352e-05\n",
      "\t\t3000\t0.6563018\t2.9152035e-05\n",
      "\t\t4000\t0.64651966\t7.836351e-06\n",
      "\t\t5000\t0.6401999\t1.2661872e-05\n",
      "\t\t6000\t0.6303319\t2.137027e-05\n",
      "\t\t7000\t0.6143509\t2.5806792e-05\n",
      "\t\t8000\t0.60139966\t1.6650181e-05\n",
      "\t\t9000\t0.59025663\t1.4238104e-05\n",
      "\t\t10000\t0.58317816\t1.05271665e-05\n",
      "\t\tFinal loss:\n",
      "\t\t10000\t0.58317816\t1.05271665e-05\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.6758109\t9.083489e-05\n",
      "\t\t2000\t0.63152355\t3.7562742e-05\n",
      "\t\t3000\t0.6170198\t1.3620536e-05\n",
      "\t\t4000\t0.6100067\t1.17252375e-05\n",
      "\t\t5000\t0.60189533\t2.832128e-05\n",
      "\t\t6000\t0.5942346\t8.826754e-06\n",
      "\t\t7000\t0.58964545\t6.671603e-06\n",
      "\t\t8000\t0.5860608\t5.491978e-06\n",
      "\t\t9000\t0.5831177\t4.701968e-06\n",
      "\t\t10000\t0.58055675\t4.2093734e-06\n",
      "\t\tFinal loss:\n",
      "\t\t10000\t0.58055675\t4.2093734e-06\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.6257624\t0.00010905078\n",
      "\t\t2000\t0.5685959\t8.7313914e-05\n",
      "\t\t3000\t0.5432839\t3.1595995e-05\n",
      "\t\t4000\t0.52878326\t2.2994427e-05\n",
      "\t\t5000\t0.51694715\t2.0869087e-05\n",
      "\t\t6000\t0.50732964\t1.5508045e-05\n",
      "\t\t7000\t0.5008129\t1.3091566e-05\n",
      "\t\t8000\t0.49530718\t8.363473e-06\n",
      "\t\t9000\t0.49159285\t6.8504646e-06\n",
      "\t\t10000\t0.47580767\t2.0669198e-05\n",
      "\t\tFinal loss:\n",
      "\t\t10000\t0.47580767\t2.0669198e-05\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.6947823\t0.00010568082\n",
      "\t\t2000\t0.6400387\t9.386282e-05\n",
      "\t\t3000\t0.5618192\t6.990988e-05\n",
      "\t\t4000\t0.533881\t2.7910237e-05\n",
      "\t\t5000\t0.5251502\t1.1576885e-05\n",
      "\t\t6000\t0.5185156\t1.459875e-05\n",
      "\t\t7000\t0.5105816\t1.4241921e-05\n",
      "\t\t8000\t0.5040359\t1.8447403e-05\n",
      "\t\t9000\t0.49382368\t2.6855087e-05\n",
      "\t\t10000\t0.4846659\t1.3466226e-05\n",
      "\t\tFinal loss:\n",
      "\t\t10000\t0.4846659\t1.3466226e-05\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.641401\t0.00011345323\n",
      "\t\t2000\t0.57545567\t9.745756e-05\n",
      "\t\t3000\t0.5273794\t0.000120804245\n",
      "\t\t4000\t0.49011153\t3.794227e-05\n",
      "\t\t5000\t0.47121912\t4.0095816e-05\n",
      "\t\t6000\t0.4418958\t4.376792e-05\n",
      "\t\t7000\t0.42965043\t1.9768382e-05\n",
      "\t\t8000\t0.42269534\t1.3043337e-05\n",
      "\t\t9000\t0.4178246\t1.0984291e-05\n",
      "\t\t10000\t0.41402164\t7.630089e-06\n",
      "\t\tFinal loss:\n",
      "\t\t10000\t0.41402164\t7.630089e-06\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.64185566\t0.00015041544\n",
      "\t\t2000\t0.5649471\t8.597904e-05\n",
      "\t\t3000\t0.5314576\t4.530782e-05\n",
      "\t\t4000\t0.51132786\t4.138005e-05\n",
      "\t\t5000\t0.4951251\t3.4127417e-05\n",
      "\t\t6000\t0.4613518\t4.8768976e-05\n",
      "\t\t7000\t0.43988594\t5.03358e-05\n",
      "\t\t8000\t0.4191516\t3.5549503e-05\n",
      "\t\t9000\t0.4075855\t2.0619187e-05\n",
      "\t\t10000\t0.4005276\t1.52533385e-05\n",
      "\t\tFinal loss:\n",
      "\t\t10000\t0.4005276\t1.52533385e-05\n",
      "\n",
      "Crossvalidation fold: 7/10\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.77075\t3.3253211e-06\n",
      "\t\t2000\t0.7669853\t6.2169925e-06\n",
      "\t\t3000\t0.763608\t1.5611296e-06\n",
      "\t\tFinal loss:\n",
      "\t\t3173\t0.76342523\t9.3690255e-07\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.79489285\t0.000120785444\n",
      "\t\t2000\t0.74724716\t2.1695781e-05\n",
      "\t\t3000\t0.739115\t6.2094928e-06\n",
      "\t\t4000\t0.7349336\t5.514911e-06\n",
      "\t\t5000\t0.7308887\t6.1162814e-06\n",
      "\t\t6000\t0.72607625\t5.6642775e-06\n",
      "\t\t7000\t0.72270495\t5.1133857e-06\n",
      "\t\t8000\t0.7177149\t7.557293e-06\n",
      "\t\t9000\t0.7123323\t7.279701e-06\n",
      "\t\t10000\t0.70758307\t5.980788e-06\n",
      "\t\tFinal loss:\n",
      "\t\t10000\t0.70758307\t5.980788e-06\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.7444926\t3.5065386e-05\n",
      "\t\t2000\t0.72622305\t3.7506798e-05\n",
      "\t\t3000\t0.68892914\t4.567932e-05\n",
      "\t\t4000\t0.6722547\t1.02848935e-05\n",
      "\t\t5000\t0.66837305\t3.4779575e-06\n",
      "\t\t6000\t0.66577363\t1.0205962e-05\n",
      "\t\tFinal loss:\n",
      "\t\t6923\t0.6581177\t9.962511e-07\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.74419624\t4.669183e-05\n",
      "\t\t2000\t0.72112757\t2.7688586e-05\n",
      "\t\t3000\t0.70356494\t1.6604461e-05\n",
      "\t\t4000\t0.6938591\t1.6922624e-05\n",
      "\t\t5000\t0.66991204\t3.6655878e-05\n",
      "\t\t6000\t0.65372956\t1.2035127e-05\n",
      "\t\t7000\t0.64898914\t5.4186653e-06\n",
      "\t\t8000\t0.645066\t5.7288194e-06\n",
      "\t\t9000\t0.6415009\t5.110264e-06\n",
      "\t\t10000\t0.63874495\t3.4526524e-06\n",
      "\t\tFinal loss:\n",
      "\t\t10000\t0.63874495\t3.4526524e-06\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.7466619\t6.242172e-05\n",
      "\t\t2000\t0.71587336\t4.445963e-05\n",
      "\t\t3000\t0.67204845\t6.82874e-05\n",
      "\t\t4000\t0.646108\t1.937251e-05\n",
      "\t\t5000\t0.6349608\t1.6145617e-05\n",
      "\t\t6000\t0.6232089\t2.151888e-05\n",
      "\t\t7000\t0.60898596\t2.7697924e-05\n",
      "\t\t8000\t0.5841545\t2.6528593e-05\n",
      "\t\t9000\t0.57336384\t1.2682478e-05\n",
      "\t\t10000\t0.56809354\t6.7148653e-06\n",
      "\t\tFinal loss:\n",
      "\t\t10000\t0.56809354\t6.7148653e-06\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.6800457\t0.0001502061\n",
      "\t\t2000\t0.61429846\t6.0930375e-05\n",
      "\t\t3000\t0.58790183\t3.2340886e-05\n",
      "\t\t4000\t0.5725044\t2.1967175e-05\n",
      "\t\t5000\t0.5614351\t1.9003139e-05\n",
      "\t\t6000\t0.5492353\t2.3874483e-05\n",
      "\t\t7000\t0.5379342\t1.7284947e-05\n",
      "\t\t8000\t0.5300074\t1.3157649e-05\n",
      "\t\t9000\t0.521758\t1.0738266e-05\n",
      "\t\t10000\t0.51643044\t2.9545776e-05\n",
      "\t\tFinal loss:\n",
      "\t\t10000\t0.51643044\t2.9545776e-05\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.7041987\t8.108027e-05\n",
      "\t\t2000\t0.6254597\t8.0329206e-05\n",
      "\t\t3000\t0.57852197\t8.519788e-05\n",
      "\t\t4000\t0.5399943\t7.70394e-05\n",
      "\t\t5000\t0.5160053\t3.291975e-05\n",
      "\t\t6000\t0.49373978\t3.4343877e-05\n",
      "\t\t7000\t0.48504046\t1.0322311e-05\n",
      "\t\t8000\t0.48071858\t7.997338e-06\n",
      "\t\t9000\t0.4770765\t7.1838426e-06\n",
      "\t\t10000\t0.47379535\t6.730389e-06\n",
      "\t\tFinal loss:\n",
      "\t\t10000\t0.47379535\t6.730389e-06\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.6801002\t0.00014099445\n",
      "\t\t2000\t0.6158124\t0.00011274794\n",
      "\t\t3000\t0.5535337\t6.2773644e-05\n",
      "\t\t4000\t0.5239815\t4.288317e-05\n",
      "\t\t5000\t0.5098825\t1.683314e-05\n",
      "\t\t6000\t0.50401163\t8.041647e-06\n",
      "\t\t7000\t0.5003293\t7.1477984e-06\n",
      "\t\t8000\t0.4930976\t1.49886455e-05\n",
      "\t\t9000\t0.4883208\t6.347102e-06\n",
      "\t\t10000\t0.4857147\t4.6631612e-06\n",
      "\t\tFinal loss:\n",
      "\t\t10000\t0.4857147\t4.6631612e-06\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.7097517\t9.371242e-05\n",
      "\t\t2000\t0.6380978\t0.000105822204\n",
      "\t\t3000\t0.5737741\t0.00012931603\n",
      "\t\t4000\t0.50948405\t8.481071e-05\n",
      "\t\t5000\t0.4795172\t5.00288e-05\n",
      "\t\t6000\t0.4605492\t3.6430625e-05\n",
      "\t\t7000\t0.44377258\t3.7740665e-05\n",
      "\t\t8000\t0.42546096\t4.342734e-05\n",
      "\t\t9000\t0.4069289\t4.2622218e-05\n",
      "\t\t10000\t0.39269623\t2.8989729e-05\n",
      "\t\tFinal loss:\n",
      "\t\t10000\t0.39269623\t2.8989729e-05\n",
      "\n",
      "Crossvalidation fold: 8/10\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.78268903\t0.00014436652\n",
      "\t\t2000\t0.76612955\t3.5787732e-06\n",
      "\t\t3000\t0.7637737\t2.4192238e-06\n",
      "\t\tFinal loss:\n",
      "\t\t3956\t0.7624905\t9.3805113e-07\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.7530644\t3.624914e-05\n",
      "\t\t2000\t0.7367073\t8.3333325e-06\n",
      "\t\t3000\t0.73166156\t5.8654296e-06\n",
      "\t\t4000\t0.7280935\t3.9294564e-06\n",
      "\t\t5000\t0.72572327\t2.6281969e-06\n",
      "\t\t6000\t0.7238416\t2.635029e-06\n",
      "\t\t7000\t0.7215615\t3.3041922e-06\n",
      "\t\t8000\t0.71916616\t3.3151975e-06\n",
      "\t\t9000\t0.716705\t3.4929103e-06\n",
      "\t\t10000\t0.7142551\t3.337992e-06\n",
      "\t\tFinal loss:\n",
      "\t\t10000\t0.7142551\t3.337992e-06\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.7322743\t0.00010702509\n",
      "\t\t2000\t0.7069057\t2.4198585e-05\n",
      "\t\t3000\t0.6876977\t3.7354555e-05\n",
      "\t\t4000\t0.6756472\t1.2438667e-05\n",
      "\t\t5000\t0.66905224\t7.305177e-06\n",
      "\t\t6000\t0.66007465\t2.2484159e-05\n",
      "\t\t7000\t0.62870526\t2.1235956e-05\n",
      "\t\t8000\t0.6214491\t6.330175e-06\n",
      "\t\t9000\t0.61899924\t2.3110015e-06\n",
      "\t\tFinal loss:\n",
      "\t\t9614\t0.61833787\t9.639485e-07\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.72210586\t0.00010968736\n",
      "\t\t2000\t0.65344375\t4.8159825e-05\n",
      "\t\t3000\t0.641009\t5.951047e-06\n",
      "\t\t4000\t0.63764644\t7.197601e-06\n",
      "\t\t5000\t0.63302165\t8.097602e-06\n",
      "\t\t6000\t0.62826025\t5.976934e-06\n",
      "\t\t7000\t0.6254482\t3.4307554e-06\n",
      "\t\t8000\t0.62369066\t2.293618e-06\n",
      "\t\t9000\t0.62257886\t1.5318105e-06\n",
      "\t\t10000\t0.6217649\t1.3420891e-06\n",
      "\t\tFinal loss:\n",
      "\t\t10000\t0.6217649\t1.3420891e-06\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.6896726\t7.397394e-05\n",
      "\t\t2000\t0.6654054\t2.5080773e-05\n",
      "\t\t3000\t0.6474731\t2.4762809e-05\n",
      "\t\t4000\t0.6255922\t4.2777614e-05\n",
      "\t\t5000\t0.60696405\t2.0425448e-05\n",
      "\t\t6000\t0.5970361\t1.4276092e-05\n",
      "\t\t7000\t0.58682275\t2.0009245e-05\n",
      "\t\t8000\t0.578168\t9.175127e-06\n",
      "\t\t9000\t0.57438844\t4.8771954e-06\n",
      "\t\t10000\t0.57191837\t3.9602987e-06\n",
      "\t\tFinal loss:\n",
      "\t\t10000\t0.57191837\t3.9602987e-06\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.7035866\t7.047828e-05\n",
      "\t\t2000\t0.64461076\t9.652529e-05\n",
      "\t\t3000\t0.60998964\t4.934323e-05\n",
      "\t\t4000\t0.5817114\t3.760298e-05\n",
      "\t\t5000\t0.5652876\t1.592138e-05\n",
      "\t\t6000\t0.55939335\t9.269964e-06\n",
      "\t\t7000\t0.5534006\t1.2170647e-05\n",
      "\t\t8000\t0.5475969\t9.360812e-06\n",
      "\t\t9000\t0.5424309\t1.0878429e-05\n",
      "\t\t10000\t0.536993\t8.32471e-06\n",
      "\t\tFinal loss:\n",
      "\t\t10000\t0.536993\t8.32471e-06\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.6837211\t0.00011549597\n",
      "\t\t2000\t0.619326\t0.00013404594\n",
      "\t\t3000\t0.5632904\t5.523244e-05\n",
      "\t\t4000\t0.5412846\t1.8389203e-05\n",
      "\t\t5000\t0.53343517\t1.3743508e-05\n",
      "\t\t6000\t0.52398294\t1.9110143e-05\n",
      "\t\t7000\t0.5166959\t1.5688347e-05\n",
      "\t\t8000\t0.5068767\t1.7285725e-05\n",
      "\t\t9000\t0.49985436\t1.1029951e-05\n",
      "\t\t10000\t0.49502924\t8.849785e-06\n",
      "\t\tFinal loss:\n",
      "\t\t10000\t0.49502924\t8.849785e-06\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.72247165\t8.4886335e-05\n",
      "\t\t2000\t0.6643015\t0.000100033685\n",
      "\t\t3000\t0.6038541\t9.662484e-05\n",
      "\t\t4000\t0.5525299\t9.2656795e-05\n",
      "\t\t5000\t0.5171112\t3.780538e-05\n",
      "\t\t6000\t0.4925394\t4.549956e-05\n",
      "\t\t7000\t0.4787429\t2.0853719e-05\n",
      "\t\t8000\t0.46830735\t2.0745683e-05\n",
      "\t\t9000\t0.4605603\t1.3071015e-05\n",
      "\t\t10000\t0.45264736\t5.3788423e-05\n",
      "\t\tFinal loss:\n",
      "\t\t10000\t0.45264736\t5.3788423e-05\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.64747053\t0.00015647359\n",
      "\t\t2000\t0.53165585\t0.00016018143\n",
      "\t\t3000\t0.4619694\t0.00015164346\n",
      "\t\t4000\t0.42388207\t5.2728257e-05\n",
      "\t\t5000\t0.40344363\t4.328586e-05\n",
      "\t\t6000\t0.38968217\t2.8449207e-05\n",
      "\t\t7000\t0.3783377\t3.741518e-05\n",
      "\t\t8000\t0.3671875\t2.426738e-05\n",
      "\t\t9000\t0.35974073\t1.7148392e-05\n",
      "\t\t10000\t0.35444635\t1.269612e-05\n",
      "\t\tFinal loss:\n",
      "\t\t10000\t0.35444635\t1.269612e-05\n",
      "\n",
      "Crossvalidation fold: 9/10\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.8117114\t0.00017245929\n",
      "\t\t2000\t0.75295925\t1.8048273e-05\n",
      "\t\tFinal loss:\n",
      "\t\t2765\t0.7444992\t9.607197e-07\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.7308926\t3.376076e-05\n",
      "\t\t2000\t0.72051775\t9.265085e-06\n",
      "\t\t3000\t0.7143419\t9.1783095e-06\n",
      "\t\t4000\t0.7088878\t5.8856995e-06\n",
      "\t\t5000\t0.70399576\t5.8419337e-06\n",
      "\t\t6000\t0.7009401\t3.2313308e-06\n",
      "\t\t7000\t0.6990314\t2.3874836e-06\n",
      "\t\t8000\t0.69762576\t1.7942217e-06\n",
      "\t\t9000\t0.6965208\t1.2836207e-06\n",
      "\t\tFinal loss:\n",
      "\t\t9973\t0.6956495\t9.425012e-07\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.74209964\t8.922636e-05\n",
      "\t\t2000\t0.7163406\t1.6557944e-05\n",
      "\t\t3000\t0.7042642\t1.7772809e-05\n",
      "\t\t4000\t0.68939793\t2.3429835e-05\n",
      "\t\t5000\t0.6762871\t1.18981e-05\n",
      "\t\t6000\t0.6715718\t4.171418e-06\n",
      "\t\tFinal loss:\n",
      "\t\t6553\t0.67078567\t9.774366e-07\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.7273686\t7.358172e-05\n",
      "\t\t2000\t0.68123215\t3.4646957e-05\n",
      "\t\t3000\t0.662643\t2.5455161e-05\n",
      "\t\t4000\t0.645064\t2.504008e-05\n",
      "\t\t5000\t0.6370772\t5.987774e-06\n",
      "\t\t6000\t0.63379997\t4.514058e-06\n",
      "\t\t7000\t0.63112617\t4.8165048e-06\n",
      "\t\t8000\t0.6248369\t9.634532e-06\n",
      "\t\t9000\t0.62062585\t5.3781873e-06\n",
      "\t\t10000\t0.6177175\t4.149128e-06\n",
      "\t\tFinal loss:\n",
      "\t\t10000\t0.6177175\t4.149128e-06\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.689739\t7.12019e-05\n",
      "\t\t2000\t0.6613236\t2.4514573e-05\n",
      "\t\t3000\t0.63620746\t2.8573852e-05\n",
      "\t\t4000\t0.610532\t5.798731e-05\n",
      "\t\t5000\t0.584509\t2.2127839e-05\n",
      "\t\t6000\t0.5750852\t1.2540874e-05\n",
      "\t\t7000\t0.56950504\t7.3261767e-06\n",
      "\t\t8000\t0.5661987\t4.631929e-06\n",
      "\t\t9000\t0.56398684\t3.3818912e-06\n",
      "\t\t10000\t0.5623346\t2.543873e-06\n",
      "\t\tFinal loss:\n",
      "\t\t10000\t0.5623346\t2.543873e-06\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.69715035\t0.00010908297\n",
      "\t\t2000\t0.6308692\t7.8790275e-05\n",
      "\t\t3000\t0.5949424\t4.868782e-05\n",
      "\t\t4000\t0.5761151\t4.0347622e-05\n",
      "\t\t5000\t0.55811745\t1.7727802e-05\n",
      "\t\t6000\t0.5458613\t3.1010066e-05\n",
      "\t\t7000\t0.5339617\t1.43997e-05\n",
      "\t\t8000\t0.5281101\t9.931938e-06\n",
      "\t\t9000\t0.5206408\t9.044094e-06\n",
      "\t\t10000\t0.5169774\t6.11057e-06\n",
      "\t\tFinal loss:\n",
      "\t\t10000\t0.5169774\t6.11057e-06\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.66767067\t0.00013728229\n",
      "\t\t2000\t0.60575294\t6.454467e-05\n",
      "\t\t3000\t0.582841\t2.9042618e-05\n",
      "\t\t4000\t0.5636712\t2.8232756e-05\n",
      "\t\t5000\t0.551346\t1.7945526e-05\n",
      "\t\t6000\t0.5426677\t1.416869e-05\n",
      "\t\t7000\t0.534851\t1.6381644e-05\n",
      "\t\t8000\t0.526436\t1.483199e-05\n",
      "\t\t9000\t0.5193415\t1.2739269e-05\n",
      "\t\t10000\t0.5130984\t1.1732639e-05\n",
      "\t\tFinal loss:\n",
      "\t\t10000\t0.5130984\t1.1732639e-05\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.6247761\t0.00024331028\n",
      "\t\t2000\t0.5266861\t0.0001639553\n",
      "\t\t3000\t0.4951733\t3.2318643e-05\n",
      "\t\t4000\t0.4849478\t1.3765663e-05\n",
      "\t\t5000\t0.47981083\t8.757807e-06\n",
      "\t\t6000\t0.4719082\t6.8389796e-05\n",
      "\t\t7000\t0.4566478\t2.134063e-05\n",
      "\t\t8000\t0.44699353\t1.2801019e-05\n",
      "\t\t9000\t0.44252554\t8.014109e-06\n",
      "\t\t10000\t0.43747452\t8.583495e-06\n",
      "\t\tFinal loss:\n",
      "\t\t10000\t0.43747452\t8.583495e-06\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.58076084\t0.00024030638\n",
      "\t\t2000\t0.5001956\t9.841868e-05\n",
      "\t\t3000\t0.45801243\t4.1251922e-05\n",
      "\t\t4000\t0.4363182\t3.360449e-05\n",
      "\t\t5000\t0.42205197\t7.442048e-05\n",
      "\t\t6000\t0.39965588\t2.3339853e-05\n",
      "\t\t7000\t0.39124334\t2.0185535e-05\n",
      "\t\t8000\t0.38417885\t1.4428571e-05\n",
      "\t\t9000\t0.37841576\t1.2679475e-05\n",
      "\t\t10000\t0.37409335\t1.0515731e-05\n",
      "\t\tFinal loss:\n",
      "\t\t10000\t0.37409335\t1.0515731e-05\n",
      "\n",
      "Crossvalidation fold: 10/10\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.7987371\t0.00014362982\n",
      "\t\t2000\t0.75934017\t1.8446059e-05\n",
      "\t\t3000\t0.7535274\t2.9267221e-06\n",
      "\t\t4000\t0.7513141\t3.0146775e-06\n",
      "\t\t5000\t0.7484733\t4.778075e-06\n",
      "\t\t6000\t0.7436939\t7.453592e-06\n",
      "\t\tFinal loss:\n",
      "\t\t6990\t0.74057645\t9.658086e-07\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.71257156\t2.55954e-05\n",
      "\t\t2000\t0.7005006\t1.2082441e-05\n",
      "\t\t3000\t0.6921929\t9.29978e-06\n",
      "\t\t4000\t0.6880612\t3.898198e-06\n",
      "\t\t5000\t0.6859046\t2.9545681e-06\n",
      "\t\t6000\t0.6837723\t3.7483092e-06\n",
      "\t\t7000\t0.6798562\t7.1890877e-06\n",
      "\t\t8000\t0.6753632\t5.8248415e-06\n",
      "\t\t9000\t0.67193913\t4.5239562e-06\n",
      "\t\t10000\t0.66917145\t3.741023e-06\n",
      "\t\tFinal loss:\n",
      "\t\t10000\t0.66917145\t3.741023e-06\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.7185478\t2.4304209e-05\n",
      "\t\t2000\t0.70456135\t2.0133974e-05\n",
      "\t\t3000\t0.6922578\t1.23124055e-05\n",
      "\t\t4000\t0.6857297\t1.1647344e-05\n",
      "\t\t5000\t0.67822796\t2.8122452e-06\n",
      "\t\t6000\t0.6766013\t2.20235e-06\n",
      "\t\t7000\t0.6746878\t3.7987793e-06\n",
      "\t\t8000\t0.67098963\t6.7511064e-06\n",
      "\t\t9000\t0.66661894\t5.9012473e-06\n",
      "\t\t10000\t0.66297084\t5.12458e-06\n",
      "\t\tFinal loss:\n",
      "\t\t10000\t0.66297084\t5.12458e-06\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.6861604\t8.034545e-05\n",
      "\t\t2000\t0.6615482\t1.4145298e-05\n",
      "\t\t3000\t0.6553799\t6.366229e-06\n",
      "\t\t4000\t0.65223473\t3.5640128e-06\n",
      "\t\t5000\t0.6501008\t3.2089729e-06\n",
      "\t\t6000\t0.6472796\t4.143801e-06\n",
      "\t\t7000\t0.64480984\t3.6050517e-06\n",
      "\t\t8000\t0.64259636\t3.3392034e-06\n",
      "\t\t9000\t0.64054406\t3.1637971e-06\n",
      "\t\t10000\t0.6380789\t8.220246e-06\n",
      "\t\tFinal loss:\n",
      "\t\t10000\t0.6380789\t8.220246e-06\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.7036121\t0.00015034185\n",
      "\t\t2000\t0.6687194\t3.5651738e-05\n",
      "\t\t3000\t0.6461791\t2.8409631e-05\n",
      "\t\t4000\t0.63184917\t1.9715346e-05\n",
      "\t\t5000\t0.61898863\t2.2050748e-05\n",
      "\t\t6000\t0.60632837\t1.6023334e-05\n",
      "\t\t7000\t0.59887636\t1.0350749e-05\n",
      "\t\t8000\t0.5925613\t1.0461058e-05\n",
      "\t\t9000\t0.58785516\t6.691921e-06\n",
      "\t\t10000\t0.58413994\t6.734482e-06\n",
      "\t\tFinal loss:\n",
      "\t\t10000\t0.58413994\t6.734482e-06\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.6582488\t0.00012992285\n",
      "\t\t2000\t0.60032487\t3.415367e-05\n",
      "\t\t3000\t0.5694265\t4.992742e-05\n",
      "\t\t4000\t0.54808575\t3.1862906e-05\n",
      "\t\t5000\t0.5351068\t2.172025e-05\n",
      "\t\t6000\t0.5206033\t3.8353177e-05\n",
      "\t\t7000\t0.5014999\t3.1376145e-05\n",
      "\t\t8000\t0.48950064\t1.7838434e-05\n",
      "\t\t9000\t0.4827658\t1.0679602e-05\n",
      "\t\t10000\t0.47872573\t6.3498105e-06\n",
      "\t\tFinal loss:\n",
      "\t\t10000\t0.47872573\t6.3498105e-06\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.67177004\t0.000117373034\n",
      "\t\t2000\t0.61198807\t4.6357924e-05\n",
      "\t\t3000\t0.5874904\t3.5711368e-05\n",
      "\t\t4000\t0.5752052\t1.6061349e-05\n",
      "\t\t5000\t0.5654539\t1.7814018e-05\n",
      "\t\t6000\t0.5547302\t1.5149938e-05\n",
      "\t\t7000\t0.5467959\t1.515176e-05\n",
      "\t\t8000\t0.53895944\t1.360264e-05\n",
      "\t\t9000\t0.53210956\t1.1649501e-05\n",
      "\t\t10000\t0.5264192\t9.850615e-06\n",
      "\t\tFinal loss:\n",
      "\t\t10000\t0.5264192\t9.850615e-06\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.6804999\t7.540887e-05\n",
      "\t\t2000\t0.63593715\t6.588592e-05\n",
      "\t\t3000\t0.5943372\t7.9722275e-05\n",
      "\t\t4000\t0.54850924\t7.4322445e-05\n",
      "\t\t5000\t0.51687557\t4.727782e-05\n",
      "\t\t6000\t0.49909064\t2.5317775e-05\n",
      "\t\t7000\t0.4895016\t1.5464042e-05\n",
      "\t\t8000\t0.482606\t1.3708957e-05\n",
      "\t\t9000\t0.47654268\t1.1632048e-05\n",
      "\t\t10000\t0.471317\t1.1128711e-05\n",
      "\t\tFinal loss:\n",
      "\t\t10000\t0.471317\t1.1128711e-05\n",
      "\n",
      "\tReplicate: 1/1\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.64151156\t0.00012225831\n",
      "\t\t2000\t0.5841908\t7.5394055e-05\n",
      "\t\t3000\t0.5443974\t7.0285954e-05\n",
      "\t\t4000\t0.49703738\t7.620325e-05\n",
      "\t\t5000\t0.48091617\t1.8900459e-05\n",
      "\t\t6000\t0.46868676\t4.005812e-05\n",
      "\t\t7000\t0.44991186\t2.5568124e-05\n",
      "\t\t8000\t0.4389737\t1.8126544e-05\n",
      "\t\t9000\t0.4309521\t1.8049026e-05\n",
      "\t\t10000\t0.42430618\t1.3344999e-05\n",
      "\t\tFinal loss:\n",
      "\t\t10000\t0.42430618\t1.3344999e-05\n"
     ]
    }
   ],
   "source": [
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "for k, (train_index, test_index) in enumerate(CV.split(X,y)): \n",
    "    print('\\nCrossvalidation fold: {0}/{1}'.format(k+1,K))    \n",
    "    \n",
    "    X_train = X[train_index,:]\n",
    "    y_train = y[train_index]\n",
    "    X_test = X[test_index,:]\n",
    "    y_test = y[test_index] \n",
    "\n",
    "\n",
    "    opt_val_err, opt_lambda, mean_w_vs_lambda, train_err_vs_lambda, test_err_vs_lambda = rlr_validate(X_train, y_train, lambdas, 10)\n",
    "    reg_error[k] = min(test_err_vs_lambda)\n",
    "    lambda_low[k] = lambdas[np.argmin(test_err_vs_lambda)]\n",
    "\n",
    "    #Xty = X_train.T @ y_train\n",
    "    #XtX = X_train.T @ X_train\n",
    "    #w_noreg[:,k] = np.linalg.solve(XtX,Xty).squeeze()\n",
    "    #Error_test[k] = loss_fn(  torch.Tensor(y_test),  torch.Tensor(X_test @ w_noreg[:,k]))\n",
    "\n",
    "\n",
    "    # Extract training and test set for current CV fold, \n",
    "    # and convert them to PyTorch tensors\n",
    "    X_train = torch.Tensor(X[train_index,:] )\n",
    "    y_train = torch.Tensor(y[train_index] )\n",
    "    X_test = torch.Tensor(X[test_index,:] )\n",
    "    y_test = torch.Tensor(y[test_index] )\n",
    "\n",
    "    error_N = np.array([])\n",
    "    for n_hidden in range(1,10):\n",
    "        model = lambda: torch.nn.Sequential(\n",
    "                            torch.nn.Linear(M, n_hidden), #M features to H hiden units\n",
    "                            # 1st transfer function, either Tanh or ReLU:\n",
    "                            torch.nn.Tanh(),                            #torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(n_hidden, 1), # H hidden units to 1 output neuron\n",
    "                            )\n",
    "\n",
    "        net, final_loss, learning_curve = train_neural_net(model,\n",
    "                                                        loss_fn,\n",
    "                                                        X=X_train,\n",
    "                                                        y=y_train,\n",
    "                                                        n_replicates=1,\n",
    "                                                        max_iter=max_iter)\n",
    "    \n",
    "        y_test_est = net(X_test) # threshold output of sigmoidal function\n",
    "        #y_test = y_test\n",
    "\n",
    "\n",
    "        error_rate = loss_fn(y_test_est,y_test).item()\n",
    "        error_N = np.append(error_N,error_rate) # store error rate for current CV fold \n",
    "\n",
    "    \n",
    "    error_baseline.append(loss_fn(torch.mean(y_train),y_test).item())\n",
    "\n",
    "    error_ann.append(error_N)\n",
    "\n",
    "error_baseline = np.array(error_baseline)\n",
    "reg_error = reg_error.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 1, Error: 0.6228, hidden layers: 2, reg: 0.8402, lambda: 100.0  baseline: 0.8131\n",
      "Fold: 2, Error: 0.5005, hidden layers: 2, reg: 0.83, lambda: 100.0  baseline: 0.8368\n",
      "Fold: 3, Error: 0.4432, hidden layers: 1, reg: 0.8444, lambda: 100.0  baseline: 0.6141\n",
      "Fold: 4, Error: 1.575, hidden layers: 8, reg: 0.7206, lambda: 100.0  baseline: 1.5982\n",
      "Fold: 5, Error: 0.6278, hidden layers: 1, reg: 0.8163, lambda: 10.0  baseline: 0.8722\n",
      "Fold: 6, Error: 0.9597, hidden layers: 1, reg: 0.7826, lambda: 10.0  baseline: 1.1513\n",
      "Fold: 7, Error: 0.7252, hidden layers: 4, reg: 0.8191, lambda: 100.0  baseline: 0.8598\n",
      "Fold: 8, Error: 0.7167, hidden layers: 1, reg: 0.8105, lambda: 10.0  baseline: 1.1115\n",
      "Fold: 9, Error: 0.8749, hidden layers: 1, reg: 0.7905, lambda: 10.0  baseline: 1.3195\n",
      "Fold: 10, Error: 0.9472, hidden layers: 4, reg: 0.7868, lambda: 10.0  baseline: 0.9269\n",
      " \n",
      "1 & 2 & 0.6228 & 100 & 0.8402 &  \\multicolumn{2}{c}{np.float64(0.8131)} \\\\\n",
      "2 & 2 & 0.5005 & 100 & 0.83 &  \\multicolumn{2}{c}{np.float64(0.8368)} \\\\\n",
      "3 & 1 & 0.4432 & 100 & 0.8444 &  \\multicolumn{2}{c}{np.float64(0.6141)} \\\\\n",
      "4 & 8 & 1.575 & 100 & 0.7206 &  \\multicolumn{2}{c}{np.float64(1.5982)} \\\\\n",
      "5 & 1 & 0.6278 & 10 & 0.8163 &  \\multicolumn{2}{c}{np.float64(0.8722)} \\\\\n",
      "6 & 1 & 0.9597 & 10 & 0.7826 &  \\multicolumn{2}{c}{np.float64(1.1513)} \\\\\n",
      "7 & 4 & 0.7252 & 100 & 0.8191 &  \\multicolumn{2}{c}{np.float64(0.8598)} \\\\\n",
      "8 & 1 & 0.7167 & 10 & 0.8105 &  \\multicolumn{2}{c}{np.float64(1.1115)} \\\\\n",
      "9 & 1 & 0.8749 & 10 & 0.7905 &  \\multicolumn{2}{c}{np.float64(1.3195)} \\\\\n",
      "10 & 4 & 0.9472 & 10 & 0.7868 &  \\multicolumn{2}{c}{np.float64(0.9269)} \\\\\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\trine\\AppData\\Local\\Temp\\ipykernel_26172\\2076898574.py:7: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  print(f\"{fn+1} & {np.argmin(err)+1} & {round(min(err),4)} & {int(lambda_low[fn])} & {round(reg_error[fn],4)} &  \\multicolumn{{2}}{{c}}{ {round(error_baseline[fn],4)} } \\\\\\\\\")\n"
     ]
    }
   ],
   "source": [
    "error_ann_min = np.empty(K)\n",
    "for fn, err in enumerate(error_ann):\n",
    "    print(f\"Fold: {fn+1}, Error: {round(min(err),4)}, hidden layers: {np.argmin(err)+1}, reg: {round(reg_error[fn],4)}, lambda: {lambda_low[fn,0]}  baseline: {round(error_baseline[fn],4)}\")\n",
    "    error_ann_min[fn] = min(err)\n",
    "print(\" \")\n",
    "for fn, err in enumerate(error_ann):\n",
    "    print(f\"{fn+1} & {np.argmin(err)+1} & {round(min(err),4)} & {int(lambda_low[fn])} & {round(reg_error[fn],4)} &  \\multicolumn{{2}}{{c}}{ {round(error_baseline[fn],4)} } \\\\\\\\\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Fold  ANN Test Error  Best h  RLR Test Error  Best lambda  \\\n",
      "0     1        0.622766       2        0.840244        100.0   \n",
      "1     2        0.500533       2        0.830008        100.0   \n",
      "2     3        0.443192       1        0.844425        100.0   \n",
      "3     4        1.575036       8        0.720578        100.0   \n",
      "4     5        0.627850       1        0.816314         10.0   \n",
      "5     6        0.959658       1        0.782591         10.0   \n",
      "6     7        0.725247       4        0.819147        100.0   \n",
      "7     8        0.716665       1        0.810483         10.0   \n",
      "8     9        0.874900       1        0.790520         10.0   \n",
      "9    10        0.947233       4        0.786772         10.0   \n",
      "\n",
      "   Baseline Test Error  \n",
      "0             0.813107  \n",
      "1             0.836785  \n",
      "2             0.614128  \n",
      "3             1.598241  \n",
      "4             0.872158  \n",
      "5             1.151260  \n",
      "6             0.859772  \n",
      "7             1.111506  \n",
      "8             1.319462  \n",
      "9             0.926934  \n"
     ]
    }
   ],
   "source": [
    "df_results = pd.DataFrame({\n",
    "    'Fold': np.arange(1, K+1),\n",
    "    'ANN Test Error': error_ann_min,\n",
    "    'Best h': [np.argmin(err)+1 for err in error_ann],\n",
    "    'RLR Test Error': reg_error,\n",
    "    'Best lambda': lambda_low.flatten(),\n",
    "    'Baseline Test Error': error_baseline\n",
    "})\n",
    "\n",
    "print(df_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% Confidence Intervals:\n",
      "[-0.2620708427 , 0.2524701632]\n",
      "[-0.3182431094 , -0.1038117178]\n",
      "[-0.4361253542 , 0.0236712064]\n",
      "P-value for error_ann_min - reg_error: 0.9672536960\n",
      "P-value for error_ann_min - error_baseline: 0.0015944433\n",
      "P-value for reg_error - error_baseline: 0.0730244222\n",
      "TtestResult(statistic=np.float64(-0.0422089698425523), pvalue=np.float64(0.9672536960191944), df=np.int64(9))\n"
     ]
    }
   ],
   "source": [
    "conf_int = lambda z: st.t.interval(confidence=0.95, df=np.size(z)-1, loc=np.mean(z), scale=st.sem(z))\n",
    "\n",
    "import scipy.stats as st\n",
    "des = 10\n",
    "print(\"95% Confidence Intervals:\")\n",
    "print(f\"[{round(conf_int(error_ann_min-reg_error)[0],des)} , {round(conf_int(error_ann_min-reg_error)[1],des)}]\")\n",
    "print(f\"[{round(conf_int(error_ann_min-error_baseline)[0],des)} , {round(conf_int(error_ann_min-error_baseline)[1],des)}]\")\n",
    "print(f\"[{round(conf_int(reg_error-error_baseline)[0],des)} , {round(conf_int(reg_error-error_baseline)[1],des)}]\")\n",
    "\n",
    "p_value_error_ann_min_reg = st.ttest_1samp(error_ann_min-reg_error, 0)[1]\n",
    "p_value_error_ann_min_baseline = st.ttest_1samp(error_ann_min-error_baseline, 0)[1]\n",
    "p_value_reg_error_baseline = st.ttest_1samp(reg_error-error_baseline, 0)[1]\n",
    "\n",
    "# Print the p-values\n",
    "print(f\"P-value for error_ann_min - reg_error: {p_value_error_ann_min_reg:.{des}f}\")\n",
    "print(f\"P-value for error_ann_min - error_baseline: {p_value_error_ann_min_baseline:.{des}f}\")\n",
    "print(f\"P-value for reg_error - error_baseline: {p_value_reg_error_baseline:.{des}f}\")\n",
    "\n",
    "print(st.ttest_1samp(error_ann_min-reg_error,0))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dtu02450",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
